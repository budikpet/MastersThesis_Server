{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse all hyperref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.zoopraha.cz/zvirata-a-expozice/lexikon-zvirat\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "animals_raw = soup.find(id=\"accordionAbeceda\")\\\n",
    "    .find_all(\"div\", class_=\"para\")\n",
    "animals_url = list()\n",
    "\n",
    "for animal in animals_raw:\n",
    "    links = animal.find_all('a')\n",
    "        \n",
    "    animals_url.extend([urlparse(link[\"href\"]) for link in links if link is not None])\n",
    "    \n",
    "len(animals_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads all HTML pages of Zoo Prague lexicon in case it gets removed\n",
    "# A version of these pages was uploaded to Google drive\n",
    "\n",
    "def get_page_from_url(url):\n",
    "    page = requests.get(url.geturl())\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    name = \"\"\n",
    "    \n",
    "    for query in url.query.split(\"&\"):\n",
    "        if \"d=\" in query:\n",
    "            name = query.replace(\"d=\", \"\")\n",
    "            break\n",
    "    \n",
    "    with open(f'pages/{name}.html', \"w\") as f:\n",
    "        f.write(soup.prettify())\n",
    "        \n",
    "for animal_url in animals_url:\n",
    "    #get_page_from_url(animal_url)\n",
    "    print(f'Done {animal_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse animal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(init=False)\n",
    "class Animal:\n",
    "    id: int = -1\n",
    "    name: str = \"–\"\n",
    "    name_latin: str = \"–\"\n",
    "    description: str = \"–\"\n",
    "    img_href: str = \"–\"\n",
    "        \n",
    "pattern = \"\\((.*?)\\)\"\n",
    "url_base = \"https://www.zoopraha.cz/\"\n",
    "animals_url = list()\n",
    "\n",
    "# Change animals_url to local storage\n",
    "def tmp_change_to_local():\n",
    "    for (dirpath, _, filenames) in os.walk(\"./pages\"):\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.abspath(os.path.join(dirpath, filename))\n",
    "            d = full_path.split(\"/\")[-1].replace(\".html\", \"\")\n",
    "            url = urlparse(f'{full_path}?{d}')\n",
    "            #print(url)\n",
    "            animals_url.append(url)\n",
    "\n",
    "def parse_animal_data(url):\n",
    "    animal = Animal()\n",
    "    page = requests.get(url.geturl())\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    animal_data = soup.find(id=\"maincontent\")\n",
    "    \n",
    "    # Name\n",
    "    parsed_name = animal_data.find(\"div\", \"mainboxtitle\").find(\"h2\").text\n",
    "    animal.name_latin = re.search(pattern, parsed_name).group(1)\n",
    "    animal.name = parsed_name.replace(f'({animal.name_latin})', \"\").strip()\n",
    "    \n",
    "    paras = animal_data.find_all(\"div\", \"para\")\n",
    "    animal.description = paras[0].find(\"strong\").text.strip()\n",
    "    animal.img_href = urljoin(url_base, paras[0].find(\"a\", \"thumbnail\")[\"href\"])\n",
    "    \n",
    "    \n",
    "    print(animal)\n",
    "    \n",
    "    return animal\n",
    "\n",
    "tmp_change_to_local()\n",
    "#parse_animal_data(animals_url[0])\n",
    "animals_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
